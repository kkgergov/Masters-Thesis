{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62283450",
   "metadata": {},
   "source": [
    "# 8-qubit experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd74fb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from third_meeting.noisy_8_qubit import get_circuits_and_outputs\n",
    "\n",
    "from utils import simulate_with_noise_3D\n",
    "from utils import DistanceVisualizer\n",
    "from utils import TransitionPointsVisualizer\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d813ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuits_and_outputs = get_circuits_and_outputs()\n",
    "# names = circuits_and_outputs['names']\n",
    "# true_circuits = circuits_and_outputs['true_circuits']\n",
    "# true_dists = circuits_and_outputs['true_dists']\n",
    "# mirrored_circuits = circuits_and_outputs['mirrored_circuits']\n",
    "# true_outputs = circuits_and_outputs['true_outputs']\n",
    "\n",
    "# noise_levels = np.linspace(0, 0.02, 21)\n",
    "\n",
    "# # Create ranges for each segment\n",
    "# ranges = [\n",
    "#     np.arange(10, 1000, 20),      # Usually big std reduction occurs here so we want to most precision\n",
    "#     np.arange(1000, 2000, 50),    # Usually completely converges in this range\n",
    "#     np.arange(2000, 3001, 100)\n",
    "# ]\n",
    "# shot_counts = np.concatenate(ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7f3e4",
   "metadata": {},
   "source": [
    "# Simulate:\n",
    "1-12:  different n_local configurations [ry, rz]\n",
    "13-18: different real_amplitudes configurations\n",
    "19:23: random circuits with increasing depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac41db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simulate circuits 0 to 23 (there might be problems with circuit 12)\n",
    "# indices = [22, 23]\n",
    "# for circuit_index in indices:\n",
    "#     mirrored_circuit = mirrored_circuits[circuit_index]\n",
    "#     true_output = true_outputs[circuit_index]\n",
    "\n",
    "#     true_circuit = true_circuits[circuit_index]\n",
    "#     true_dist = true_dists[circuit_index]\n",
    "\n",
    "#     hellinger_data = simulate_with_noise_3D(\n",
    "#              true_circuit, true_dist, noise_levels=noise_levels, shot_counts=shot_counts, distance_type='hellinger'\n",
    "#     )\n",
    "\n",
    "#     hamming_data = []\n",
    "#     for i in range(10):\n",
    "#         print(f\"Simulation run {i+1}/10 for circuit index {circuit_index}\")\n",
    "#         H = simulate_with_noise_3D(\n",
    "#             mirrored_circuit, true_output, noise_levels=noise_levels, shot_counts=shot_counts, distance_type='hamming'\n",
    "#         )\n",
    "#         hamming_data.append(H)\n",
    "\n",
    "#     np.savez_compressed(\n",
    "#         f'../data/third_meeting/circuit_{circuit_index}_data.npz',\n",
    "#         name=circuits_and_outputs['names'][circuit_index],\n",
    "#         shots_array=shot_counts,\n",
    "#         noise_intensities=noise_levels,\n",
    "#         hamming_data=hamming_data,\n",
    "#         hellinger_data=hellinger_data\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8dd1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load all circuit data and put it into one file\n",
    "\n",
    "# shots_dataset = []\n",
    "# noise_dataset = []\n",
    "# names_dataset = []\n",
    "# hamming_dataset = []\n",
    "# hellinger_dataset = []\n",
    "\n",
    "# # Load circuits 0 to 23\n",
    "# for circuit_index in range(0, 24):\n",
    "#     loaded = np.load(f'../data/third_meeting/circuit_{circuit_index}_data.npz', allow_pickle=True)\n",
    "#     shots_dataset.append(loaded['shots_array'])\n",
    "#     noise_dataset.append(loaded['noise_intensities'])\n",
    "#     names_dataset.append(loaded['name'].item())\n",
    "#     hamming_dataset.append(loaded['hamming_data'])\n",
    "#     hellinger_dataset.append(loaded['hellinger_data'])\n",
    "\n",
    "# # Save all data into one file\n",
    "# np.savez_compressed(\n",
    "#     f'../data/third_meeting/all_circuits_data.npz',\n",
    "#     names=names_dataset,\n",
    "#     shots_dataset=shots_dataset,\n",
    "#     noise_dataset=noise_dataset,\n",
    "#     hamming_data=hamming_dataset,\n",
    "#     hellinger_data=hellinger_dataset\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6444dc",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86964b6",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6547d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all circuits and visualize\n",
    "loaded = np.load(f'../data/third_meeting/all_circuits_data.npz', allow_pickle=True)\n",
    "names_dataset = loaded['names']\n",
    "shots_dataset = loaded['shots_dataset']\n",
    "noise_dataset = loaded['noise_dataset']\n",
    "hamming_dataset = loaded['hamming_data']\n",
    "hellinger_dataset = loaded['hellinger_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500136a9",
   "metadata": {},
   "source": [
    "## I. Difficulties on perfect quantum computers\n",
    "Lets have a look at our Hellinger distance when we have a perfect quantum computer (no erros).  \n",
    "Different circuits have different output distributions and some distributions require more samples to be \"spotted\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4023fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis1_indices = [21, 22, 23, 19]\n",
    "# for i in vis1_indices:\n",
    "#     visualizer = DistanceVisualizer(shots_dataset[i], noise_dataset[i], names_dataset[i], hamming_dataset[i], hellinger_dataset[i], 8)\n",
    "#     visualizer.create_dashboard(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ccd52c",
   "metadata": {},
   "source": [
    "# Now let us formally define the task (on a perfect quantum computer):\n",
    "\n",
    "In the case of a perfect quantum computer we just have an ideal distribution and we take increasing number of samples from it.  \n",
    "Due to the curse of dimensionality lower number of samples naturally leads to \"noisy\" sampled distribution so our Hellinger is high.  \n",
    "**Important note:** With no depolarizing error the Hellinger distance is mathematically proven to converge to 0 as we increase the number of shots.\n",
    "\n",
    "The steep drop is the **bias reduction phase** where you learn the distribution's structure. (basically sample has been seen/has not been seen)  \n",
    "The slow convergence is the **variance reduction phase** where you refine the probability estimates.\n",
    "\n",
    "<div>\n",
    "<img src=\"../data/third_meeting/images/bias_variance1.jpg\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "What we are looking for is the so called **transition point** between these two, usually after this point the error-decay\n",
    "stablizes to a 1/n-like rate.  \n",
    "Teoretically, the transition point is determined by the distribution's complexity (dimensionality, smoothness, smallest probability mass).  \n",
    "\n",
    "Some distributions that require lot of samples to estimate properly - Cauchy's distribution (next meeting with worked example on discrete Cauchy):  \n",
    "<div>\n",
    "<img src=\"../data/third_meeting/images/cauchy.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fd118",
   "metadata": {},
   "source": [
    "Now let's have a look at the output distributions of the above circuits (21, 22, 23, 19):  \n",
    "Unfortunately i didn't save their outputs, only Hellinger and Hamming distances :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e06e9",
   "metadata": {},
   "source": [
    "## II. Noisy Quantum computers\n",
    "It's mathematically proveable that a small error in sampling induces a non-zero lower bound on the Hellinger distance that does not vanish, even with infinitely many samples.  \n",
    "However, having noise allows us to calculate Hamming distance which may potentially help us determine the curvature of our Hellinger.  \n",
    "We must take a look how the noise affects the transition point, because we need to use noise in order to get Hamming curves.  \n",
    "If the transition point of Hellinger is larely invariant to noise and If the same holds for our Hamming(or it's std) we can then start to look at how well-correlated they are.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d329f65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kgergov/TUM/Masters-Thesis/notebooks/../src/utils.py:427: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  params_opt, params_cov = curve_fit(\n"
     ]
    }
   ],
   "source": [
    "# Visualize transition points of Hellinger of all circuits with graphs stacked under each other\n",
    "visualizer2 = TransitionPointsVisualizer(names_dataset, shots_dataset, noise_dataset, hamming_dataset, hellinger_dataset, 8)\n",
    "# visualizer2.hellinger_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e16f250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb3ae45b9164b32accd3c5dd3a4bf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Circuit:', options=((np.str_('QFT'), 0), (np.str_('varQC_linear_2r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example graph of circuit with both points marked\n",
    "visualizer2.transition_points_dashboard(tolerance=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a08cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c917822f16584ee9858d9721357210bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Circuit:', options=((np.str_('QFT'), 0), (np.str_('varQC_linear_2r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's artificially smooth the data and look at it again\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Apply Savitzky-Golay filter twice before visualizing for stronger smoothing\n",
    "smoothed_hellinger = [savgol_filter(hellinger_data, 11, 2) for hellinger_data in hellinger_dataset]\n",
    "\n",
    "# Smooth Hamming dataset with savgol filter as well\n",
    "smoothed_hamming = [savgol_filter(hamming_data, 11, 2) for hamming_data in hamming_dataset]\n",
    "\n",
    "visualizer3 = TransitionPointsVisualizer(names_dataset, shots_dataset, noise_dataset, smoothed_hamming, smoothed_hellinger, 8)\n",
    "visualizer3.transition_points_dashboard(tolerance=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7938c41",
   "metadata": {},
   "source": [
    "Possible next steps: finely-grained simulations in the 0-3000 shots range on more powerful computer for verification.\n",
    "Number of hamming experiments should also be increased for smoother std "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
